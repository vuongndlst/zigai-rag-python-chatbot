// app/api/chat/route.ts
import { NextResponse } from "next/server";
import { getServerSession } from "next-auth";
import { authOptions } from "@/lib/auth";

import OpenAI from "openai";
import { DataAPIClient } from "@datastax/astra-db-ts";
import {
  createChat,
  appendMessage,
  updateChatTitle,
} from "@/lib/chatService";

export const runtime = "nodejs";

const {
  OPENAI_API_KEY,
  OPENAI_CHAT_MODEL = "gpt-4o-mini",
  OPENAI_FALLBACK_MODEL = "gpt-4o",
  ASTRA_DB_API_ENDPOINT,
  ASTRA_DB_APPLICATION_TOKEN,
  ASTRA_DB_NAMESPACE,
  ASTRA_DB_COLLECTION,
  EMBEDDING_MODEL = "text-embedding-3-small",
} = process.env;

if (!OPENAI_API_KEY) throw new Error("OPENAI_API_KEY missing");
if (!ASTRA_DB_API_ENDPOINT) throw new Error("ASTRA_DB_API_ENDPOINT missing");

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });
const astra = new DataAPIClient(ASTRA_DB_APPLICATION_TOKEN!);
const vectorColl = astra
  .db(ASTRA_DB_API_ENDPOINT!, { namespace: ASTRA_DB_NAMESPACE })
  .collection(ASTRA_DB_COLLECTION!);

function escapeRegExp(text: string): string {
  return text.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
}

function containsKeywordExact(text: string, keywords: string[]): boolean {
  return keywords.some((kw) => {
    const escaped = escapeRegExp(kw);
    const regex = new RegExp(`\\b${escaped}\\b`, "i");
    return regex.test(text);
  });
}

function isTooLong(message: string): boolean {
  return message.length > 2000;
}

function isOffTopic(message: string): boolean {
  const forbiddenKeywords = ["deepfake", "chÃ­nh trá»‹", "game", "tÃ¡n gáº«u", "giáº£i trÃ­", "hacking", "an ninh máº¡ng"];
  return containsKeywordExact(message.toLowerCase(), forbiddenKeywords);
}

function isCheatingPrompt(message: string): boolean {
  const cheatHints = ["giáº£i há»™", "lÃ m giÃ¹m", "copy bÃ i", "chÃ©p lá»i giáº£i", "Ä‘Ã¡p Ã¡n lÃ  gÃ¬"];
  return cheatHints.some(h => message.toLowerCase().includes(h));
}

async function createEmbedding(text: string) {
  const { data } = await openai.embeddings.create({
    model: EMBEDDING_MODEL,
    input: text,
    encoding_format: "float",
  });
  return data[0].embedding;
}

async function runChat(model: string, messages: any[]) {
  return openai.chat.completions.create({
    model,
    messages,
    stream: false,
    max_tokens: 4096,
  });
}

export async function POST(req: Request) {
  try {
    const session = await getServerSession(authOptions);
    if (!session)
      return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
    const userId = session.user.id;

    const { messages, chatId: incomingId } = await req.json();
    if (!Array.isArray(messages) || messages.length === 0)
      return NextResponse.json({ error: "messages array required" }, { status: 400 });

    const latest = messages.at(-1).content as string;

    if (isTooLong(latest)) {
      return NextResponse.json({ answer: "CÃ¢u há»i quÃ¡ dÃ i, vui lÃ²ng chia nhá» ná»™i dung.", chatId: null, sources: [] });
    }

    if (isOffTopic(latest)) {
      return NextResponse.json({ answer: "Xin lá»—i, ZigAI chá»‰ há»— trá»£ Python THPT.", chatId: null, sources: [] });
    }

    if (isCheatingPrompt(latest)) {
      return NextResponse.json({ answer: "ZigAI khuyáº¿n khÃ­ch tá»± suy nghÄ©. MÃ¬nh cÃ³ thá»ƒ gá»£i Ã½ cÃ¡ch tiáº¿p cáº­n.", chatId: null, sources: [] });
    }

    let chatId = incomingId;
    if (!chatId) {
      const chat = await createChat(userId);
      chatId = chat._id.toString();
      const title = latest.length > 30 ? latest.slice(0, 30).trimEnd() + "â€¦" : latest;
      await updateChatTitle(chatId, userId, title);
    }

    await appendMessage(chatId, userId, "user", latest);

    let docContext = "";
    let topChunks: any[] = [];
    try {
      const emb = await createEmbedding(latest);
      const docs = await vectorColl
        .find(null, {
          sort: { $vector: emb },
          limit: 12,
          includeSimilarity: true,
        })
        .toArray();

      const uniqueSources = new Map<string, any>();
      for (const d of docs) {
        if (!uniqueSources.has(d.source)) {
          uniqueSources.set(d.source, {
            id: String(d._id),
            text: d.text,
            source: d.source,
            score: d?.$similarity ?? 0,
          });
        }
      }
      topChunks = Array.from(uniqueSources.values())
        .sort((a, b) => b.score - a.score)
        .slice(0, 8);

      docContext = topChunks.map((d, i) => `[${i + 1}] ${d.text}`).join("\n---\n");
    } catch (e) {
      console.error("Vector search error:", e);
    }

    const systemMsg = {
      role: "system" as const,
      content: `
Báº¡n lÃ  **ZigAI** â€“ trá»£ lÃ½ dáº¡y Python cho há»c sinh **THPT Viá»‡t Nam**.

ðŸŽ¯ Má»—i cÃ¢u tráº£ lá»i cáº§n:
1. **Giáº£i thÃ­ch khÃ¡i niá»‡m** dá»… hiá»ƒu, vÃ­ dá»¥ gáº§n gÅ©i, trÃ¡nh jargon.
2. **Code Python** ngáº¯n (â‰¤ 20 dÃ²ng), cÃ³ chÃº thÃ­ch tiáº¿ng Viá»‡t.
3. **TÃ³m táº¯t nhanh** (â‰¤ 3 cÃ¢u).
4. **BÃ i táº­p luyá»‡n táº­p**: 1 cÆ¡ báº£n + 1 váº­n dá»¥ng. **KhÃ´ng giáº£i bÃ i**, chá»‰ gá»£i Ã½ cÃ¡ch lÃ m.
5. **CÃ¢u há»i tá»± kiá»ƒm tra** (Yes/No hoáº·c multiple choice A/B/C/D).

ðŸ“Œ Äá»‹nh dáº¡ng Markdown. Code Ä‘áº·t trong \`\`\`python. KHÃ”NG chÃ¨n hÃ¬nh áº£nh.
ðŸ”’ KhÃ´ng tráº£ lá»i cÃ¡c chá»§ Ä‘á» ngoÃ i Python THPT á»Ÿ Viá»‡t Nam. KhÃ´ng giÃºp lÃ m bÃ i há»™.
--- NGUá»’N
${docContext}
---`
    };

    let chatRes;
    try {
      chatRes = await runChat(OPENAI_CHAT_MODEL, [systemMsg, ...messages]);
    } catch (err) {
      console.warn("Model error â€“ fallback:", err);
      chatRes = await runChat(OPENAI_FALLBACK_MODEL, [systemMsg, ...messages]);
    }

    let answer = chatRes.choices[0]?.message?.content ?? "(KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i)";

    const sources = topChunks.map((chunk, index) => ({
      id: chunk.id,
      source: chunk.source,
      snippet: chunk.text.slice(0, 160) + "â€¦",
      label: `[${index + 1}]`
    }));

    if (sources.length > 0 && !answer.includes("ðŸ”— Nguá»“n tham kháº£o")) {
  const sourceText =
    "\n\n---\n**ðŸ”— Nguá»“n tham kháº£o:**  \n" +
    sources.map((s) => `${s.label} ${s.source}`).join("  \n");
  answer += sourceText;
}

    await appendMessage(chatId, userId, "assistant", answer);
    return NextResponse.json({ answer, chatId, sources });
  } catch (err) {
    console.error("Chat route error:", err);
    return NextResponse.json({ error: "Internal server error" }, { status: 500 });
  }
}
