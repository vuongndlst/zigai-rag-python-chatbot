// app/api/chat/route.ts
import { NextResponse } from "next/server";
import { getServerSession } from "next-auth";
import { authOptions } from "@/lib/auth";

import OpenAI from "openai";
import { DataAPIClient } from "@datastax/astra-db-ts";
import {
  createChat,
  appendMessage,
  updateChatTitle,
} from "@/lib/chatService";

export const runtime = "nodejs";

const {
  OPENAI_API_KEY,
  OPENAI_CHAT_MODEL = "gpt-4o-mini",
  OPENAI_FALLBACK_MODEL = "gpt-4o",
  ASTRA_DB_API_ENDPOINT,
  ASTRA_DB_APPLICATION_TOKEN,
  ASTRA_DB_NAMESPACE,
  ASTRA_DB_COLLECTION,
  EMBEDDING_MODEL = "text-embedding-3-small",
} = process.env;

if (!OPENAI_API_KEY) throw new Error("OPENAI_API_KEY missing");
if (!ASTRA_DB_API_ENDPOINT) throw new Error("ASTRA_DB_API_ENDPOINT missing");

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });
const astra = new DataAPIClient(ASTRA_DB_APPLICATION_TOKEN!);
const vectorColl = astra
  .db(ASTRA_DB_API_ENDPOINT!, { namespace: ASTRA_DB_NAMESPACE })
  .collection(ASTRA_DB_COLLECTION!);

function escapeRegExp(text: string): string {
  return text.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
}

function containsKeywordExact(text: string, keywords: string[]): boolean {
  return keywords.some((kw) => {
    const escaped = escapeRegExp(kw);
    const regex = new RegExp(`\\b${escaped}\\b`, "i");
    return regex.test(text);
  });
}

function isTooLong(message: string): boolean {
  return message.length > 2000;
}

function isOffTopic(message: string): boolean {
  const forbiddenKeywords = ["deepfake", "ch√≠nh tr·ªã", "game", "t√°n g·∫´u", "gi·∫£i tr√≠", "hacking", "an ninh m·∫°ng"];
  return containsKeywordExact(message.toLowerCase(), forbiddenKeywords);
}

function isCheatingPrompt(message: string): boolean {
  const cheatHints = ["gi·∫£i h·ªô", "l√†m gi√πm", "copy b√†i", "ch√©p l·ªùi gi·∫£i", "ƒë√°p √°n l√† g√¨"];
  return cheatHints.some(h => message.toLowerCase().includes(h));
}

async function createEmbedding(text: string) {
  const { data } = await openai.embeddings.create({
    model: EMBEDDING_MODEL,
    input: text,
    encoding_format: "float",
  });
  return data[0].embedding;
}

async function runChat(model: string, messages: any[]) {
  return openai.chat.completions.create({
    model,
    messages,
    stream: false,
    max_tokens: 4096,
  });
}

export async function POST(req: Request) {
  try {
    const session = await getServerSession(authOptions);
    if (!session)
      return NextResponse.json({ error: "Unauthorized" }, { status: 401 });
    const userId = session.user.id;

    const { messages, chatId: incomingId } = await req.json();
    if (!Array.isArray(messages) || messages.length === 0)
      return NextResponse.json({ error: "messages array required" }, { status: 400 });

    const latest = messages.at(-1).content as string;

    if (isTooLong(latest)) {
      return NextResponse.json({ answer: "C√¢u h·ªèi qu√° d√†i, vui l√≤ng chia nh·ªè n·ªôi dung.", chatId: null, sources: [] });
    }

    if (isOffTopic(latest)) {
      return NextResponse.json({ answer: "Xin l·ªói, ZigAI ch·ªâ h·ªó tr·ª£ Python THPT.", chatId: null, sources: [] });
    }

    if (isCheatingPrompt(latest)) {
      return NextResponse.json({ answer: "ZigAI khuy·∫øn kh√≠ch t·ª± suy nghƒ©. M√¨nh c√≥ th·ªÉ g·ª£i √Ω c√°ch ti·∫øp c·∫≠n.", chatId: null, sources: [] });
    }

    let chatId = incomingId;
    if (!chatId) {
      const chat = await createChat(userId);
      chatId = chat._id.toString();
      const title = latest.length > 30 ? latest.slice(0, 30).trimEnd() + "‚Ä¶" : latest;
      await updateChatTitle(chatId, userId, title);
    }

    await appendMessage(chatId, userId, "user", latest);

    let docContext = "";
    let topChunks: any[] = [];
    try {
      const emb = await createEmbedding(latest);
      const docs = await vectorColl
        .find(null, {
          sort: { $vector: emb },
          limit: 12,
          includeSimilarity: true,
        })
        .toArray();

      const uniqueSources = new Map<string, any>();
      for (const d of docs) {
        if (!uniqueSources.has(d.source)) {
          uniqueSources.set(d.source, {
            id: String(d._id),
            text: d.text,
            source: d.source,
            score: d?.$similarity ?? 0,
          });
        }
      }
      topChunks = Array.from(uniqueSources.values())
        .sort((a, b) => b.score - a.score)
        .slice(0, 8);

      docContext = topChunks.map((d, i) => `[${i + 1}] ${d.text}`).join("\n---\n");
    } catch (e) {
      console.error("Vector search error:", e);
    }

    const systemMsg = {
      role: "system" as const,
      content: `
B·∫°n l√† **ZigAI** ‚Äì tr·ª£ l√Ω d·∫°y Python cho h·ªçc sinh **THPT Vi·ªát Nam**.

üéØ M·ªói c√¢u tr·∫£ l·ªùi c·∫ßn:
1. **Gi·∫£i th√≠ch kh√°i ni·ªám** d·ªÖ hi·ªÉu, v√≠ d·ª• g·∫ßn g≈©i, tr√°nh jargon.
2. **Code Python** ng·∫Øn (‚â§ 20 d√≤ng), c√≥ ch√∫ th√≠ch ti·∫øng Vi·ªát.
3. **T√≥m t·∫Øt nhanh** (‚â§ 3 c√¢u).
4. **B√†i t·∫≠p luy·ªán t·∫≠p**: 1 c∆° b·∫£n + 1 v·∫≠n d·ª•ng. **Kh√¥ng gi·∫£i b√†i**, ch·ªâ g·ª£i √Ω c√°ch l√†m.
5. **C√¢u h·ªèi t·ª± ki·ªÉm tra** (Yes/No ho·∫∑c multiple choice A/B/C/D).

üìå ƒê·ªãnh d·∫°ng Markdown. Code ƒë·∫∑t trong \`\`\`python. KH√îNG ch√®n h√¨nh ·∫£nh.
üîí Kh√¥ng tr·∫£ l·ªùi c√°c ch·ªß ƒë·ªÅ ngo√†i Python THPT ·ªü Vi·ªát Nam. Kh√¥ng gi√∫p l√†m b√†i h·ªô.
--- NGU·ªíN
${docContext}
---`
    };

    let chatRes;
    try {
      chatRes = await runChat(OPENAI_CHAT_MODEL, [systemMsg, ...messages]);
    } catch (err) {
      console.warn("Model error ‚Äì fallback:", err);
      chatRes = await runChat(OPENAI_FALLBACK_MODEL, [systemMsg, ...messages]);
    }

    let answer = chatRes.choices[0]?.message?.content ?? "(Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi)";

    const sources = topChunks.map((chunk, index) => ({
      id: chunk.id,
      source: chunk.source,
      snippet: chunk.text.slice(0, 160) + "‚Ä¶",
      label: `[${index + 1}]`
    }));

    // Lo·∫°i b·ªè ph·∫ßn "üîó Ngu·ªìn tham kh·∫£o" c≈© (n·∫øu c√≥)
answer = answer.replace(/\n*---\n\*\*üîó Ngu·ªìn tham kh·∫£o:\*\*[\s\S]*$/g, "");

if (sources.length > 0) {
  const sourceText =
    "\n\n---\n**üîó Ngu·ªìn tham kh·∫£o:**  \n" +
    sources
      .map((s) => {
        const normalizedSource = s.source.replace(/\\/g, "/");
        const isPdf = normalizedSource.toLowerCase().endsWith(".pdf");
        const link = isPdf
          ? `https://github.com/vuongndlst/zigai-rag-python-chatbot/blob/main/${encodeURIComponent(normalizedSource)}`
          : normalizedSource.startsWith("http")
          ? normalizedSource
          : null;

        // N·∫øu kh√¥ng c√≥ link h·ª£p l·ªá, ch·ªâ hi·ªÉn th·ªã t√™n
        if (!link) return `${s.label} ${normalizedSource}`;

        return `${s.label} [${normalizedSource}](${link})`;
      })
      .join("  \n");

  answer += sourceText;
}


    await appendMessage(chatId, userId, "assistant", answer);
    return NextResponse.json({ answer, chatId, sources });
  } catch (err) {
    console.error("Chat route error:", err);
    return NextResponse.json({ error: "Internal server error" }, { status: 500 });
  }
}
